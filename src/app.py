import streamlit as st
from textblob import TextBlob
import pandas as pd
import plotly.graph_objects as go
from datetime import datetime
import requests
import praw  # æ–°å¢: Reddit API åº“

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="Sentiment Compass: èˆ†è®ºä¿¡å¿µç½—ç›˜",
    page_icon="ğŸ§­",
    layout="wide"
)

# --- æ ¸å¿ƒé€»è¾‘å‡½æ•° (NLP) ---
def analyze_sentiment(text):
    """
    ä½¿ç”¨ TextBlob è¿›è¡ŒåŸºç¡€æƒ…ç»ªåˆ†æã€‚
    Return: polarity (-1 to 1), subjectivity (0 to 1)
    """
    if not text:
        return 0, 0
    blob = TextBlob(text)
    return blob.sentiment.polarity, blob.sentiment.subjectivity

def get_sentiment_label(score):
    if score > 0.1:
        return "ç§¯æ (Positive) ğŸŸ¢"
    elif score < -0.1:
        return "æ¶ˆæ (Negative) ğŸ”´"
    else:
        return "ä¸­æ€§ (Neutral) âšª"

# --- æ•°æ®æº A: NewsAPI (æœºæ„/å®˜æ–¹å£å¾„) ---
def fetch_news_data(topic, api_key):
    if not api_key:
        return pd.DataFrame()
    
    url = f"https://newsapi.org/v2/everything?q={topic}&language=en&sortBy=publishedAt&pageSize=50&apiKey={api_key}"
    try:
        response = requests.get(url)
        data = response.json()
        if data.get("status") != "ok":
            st.error(f"NewsAPI Error: {data.get('message')}")
            return pd.DataFrame()
        
        articles = data.get("articles", [])
        processed_data = []
        for article in articles:
            title = article.get("title", "")
            desc = article.get("description", "") or ""
            date_str = article.get("publishedAt", "")[:10] # YYYY-MM-DD
            full_text = f"{title}. {desc}"
            
            pol, subj = analyze_sentiment(full_text)
            processed_data.append({
                "Date": date_str,
                "Text": title,
                "Sentiment": pol,
                "Subjectivity": subj,
                "Source": "News (Institutional)"
            })
        return pd.DataFrame(processed_data)
    except Exception as e:
        st.error(f"NewsAPI è¯·æ±‚å¤±è´¥: {e}")
        return pd.DataFrame()

# --- æ•°æ®æº B: Reddit (å¤§ä¼—/æ•£æˆ·å£å¾„) ---
def fetch_reddit_data(topic, client_id, client_secret, user_agent="sentiment_compass_v1"):
    if not client_id or not client_secret:
        return pd.DataFrame()
    
    try:
        reddit = praw.Reddit(
            client_id=client_id,
            client_secret=client_secret,
            user_agent=user_agent
        )
        # æœç´¢ r/allï¼ŒæŒ‰ 'new' æ’åºä»¥æ•æ‰æœ€æ–°ä¿¡å·
        # limit=50 ä¿è¯æ ·æœ¬é‡ä¸æ–°é—»å¯¹ç­‰
        submissions = reddit.subreddit("all").search(topic, sort="new", limit=50)
        
        processed_data = []
        for sub in submissions:
            # ç»“åˆæ ‡é¢˜å’Œæ­£æ–‡ï¼Œæ›´çœŸå®åæ˜ ç”¨æˆ·æƒ³æ³•
            full_text = f"{sub.title} . {sub.selftext}"
            pol, subj = analyze_sentiment(full_text)
            
            # Reddit ä½¿ç”¨ UTC æ—¶é—´æˆ³
            date_str = datetime.fromtimestamp(sub.created_utc).strftime('%Y-%m-%d')
            
            processed_data.append({
                "Date": date_str,
                "Text": sub.title,
                "Sentiment": pol,
                "Subjectivity": subj,
                "Source": "Reddit (Public/Retail)"
            })
        return pd.DataFrame(processed_data)
    except Exception as e:
        st.error(f"Reddit API è¿æ¥å¤±è´¥: {e}")
        return pd.DataFrame()

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("âš™ï¸ æ•°æ®æºé…ç½®")
    st.info("ğŸ’¡ **åŸç†**ï¼šæ¯”è¾ƒâ€œå®˜æ–¹æŠ¥é“â€ä¸â€œæ°‘é—´è®¨è®ºâ€çš„æƒ…ç»ªå·®å€¼ï¼Œå¯»æ‰¾å…±æŒ¯æˆ–èƒŒç¦»ä¿¡å·ã€‚")
    
    st.subheader("1. æœºæ„ä¿¡å· (NewsAPI)")
    news_api_key = st.text_input("NewsAPI Key", type="password", help="å¿…å¡«ï¼Œç”¨äºè·å–æ–°é—»")
    
    st.subheader("2. å¾®å¼±ä¿¡å· (Reddit)")
    reddit_cid = st.text_input("Reddit Client ID", type="password")
    reddit_secret = st.text_input("Reddit Secret", type="password")
    
    st.markdown("---")
    st.caption("æ²¡æœ‰ Key? ä»…ä½¿ç”¨å•ç‚¹åˆ†æåŠŸèƒ½ä¸å—å½±å“ã€‚")

# --- ä¸»é¡µé¢ ---
st.title("ğŸ§­ èˆ†è®ºä¿¡å¿µç½—ç›˜ (Sentiment Compass)")
st.markdown("> *\"The market is a voting machine in the short run, but a weighing machine in the long run.\"* â€” Benjamin Graham")

tab1, tab2 = st.tabs(["ğŸ” å•ç‚¹å—…æ¢ (Sniffer)", "ğŸ“ˆ è¶‹åŠ¿å…±æŒ¯ (Resonance)"])

# --- Tab 1: å•ç‚¹åˆ†æ (ä¿æŒåŸæ ·ï¼Œç•¥å¾®ä¼˜åŒ–å±•ç¤º) ---
with tab1:
    st.subheader("å³æ—¶æ–‡æœ¬æƒ…ç»ªæ¢æµ‹")
    user_input = st.text_area("è¾“å…¥ä¸€æ¡ä¼ è¨€ã€è¯„è®ºæˆ–æ–°é—»æ ‡é¢˜ï¼š", height=100)
    
    if st.button("åˆ†æ"):
        if user_input:
            pol, subj = analyze_sentiment(user_input)
            label = get_sentiment_label(pol)
            
            c1, c2, c3 = st.columns(3)
            c1.metric("æƒ…ç»ªææ€§ (Polarity)", f"{pol:.2f}")
            c2.metric("ä¸»è§‚å™ªéŸ³ (Subjectivity)", f"{subj:.2f}", help="è¶Šæ¥è¿‘ 1 ä»£è¡¨è¶Šä¸»è§‚/æƒ…ç»ªåŒ–")
            c3.subheader(label)
            
            # ä»ªè¡¨ç›˜
            fig = go.Figure(go.Indicator(
                mode = "gauge+number", value = pol,
                title = {'text': "ä¿¡å¿µå¼ºåº¦"},
                gauge = {'axis': {'range': [-1, 1]}, 'bar': {'color': "black"},
                         'steps': [{'range': [-1, -0.2], 'color': "#ff4b4b"},
                                   {'range': [-0.2, 0.2], 'color': "#f0f2f6"},
                                   {'range': [0.2, 1], 'color': "#2bd27f"}]}
            ))
            st.plotly_chart(fig, use_container_width=True)

# --- Tab 2: è¶‹åŠ¿åˆ†æ (æ ¸å¿ƒä¿®æ”¹) ---
with tab2:
    st.subheader("ğŸŒ å®è§‚èˆ†è®ºåœºï¼šæœºæ„ vs æ•£æˆ·")
    
    col_in, col_btn = st.columns([3, 1])
    with col_in:
        topic = st.text_input("è¾“å…¥èµ„äº§æˆ–è¯é¢˜ (ä¾‹å¦‚: Quantum Computing, Inflation)", value="Gold")
    with col_btn:
        start_btn = st.button("å¼€å§‹å…¨ç½‘æ‰«æ", type="primary")

    if start_btn:
        if not news_api_key and not (reddit_cid and reddit_secret):
            st.error("è¯·è‡³å°‘åœ¨ä¾§è¾¹æ é…ç½®ä¸€ä¸ª API Key (NewsAPI æˆ– Reddit)ï¼")
        else:
            with st.spinner(f"æ­£åœ¨æ‰«æ '{topic}' çš„å¤šç»´èˆ†è®ºä¿¡å·..."):
                # 1. è·å–æ•°æ®
                df_news = fetch_news_data(topic, news_api_key)
                df_reddit = fetch_reddit_data(topic, reddit_cid, reddit_secret)
                
                # 2. åˆå¹¶æ•°æ®
                df_all = pd.concat([df_news, df_reddit], ignore_index=True)
                
                if not df_all.empty:
                    # 3. æ•°æ®èšåˆï¼šæŒ‰æ—¥æœŸå’Œæ¥æºè®¡ç®—å¹³å‡æƒ…ç»ª
                    df_all['Date'] = pd.to_datetime(df_all['Date'])
                    df_trend = df_all.groupby(['Date', 'Source'])['Sentiment'].mean().reset_index()
                    
                    st.success(f"æ‰«æå®Œæˆï¼å…±åˆ†æ {len(df_all)} æ¡æ•°æ® (News: {len(df_news)}, Reddit: {len(df_reddit)})")
                    
                    # 4. ç»˜åˆ¶å¯¹æ¯”å›¾
                    fig_trend = go.Figure()
                    
                    # åªæœ‰æ–°é—»æ•°æ®æ—¶
                    if not df_news.empty:
                        news_trend = df_trend[df_trend['Source'] == 'News (Institutional)']
                        fig_trend.add_trace(go.Scatter(
                            x=news_trend['Date'], y=news_trend['Sentiment'],
                            mode='lines+markers', name='æ–°é—» (æœºæ„/æ»å)',
                            line=dict(color='#1f77b4', width=3)
                        ))
                    
                    # åªæœ‰ Reddit æ•°æ®æ—¶
                    if not df_reddit.empty:
                        reddit_trend = df_trend[df_trend['Source'] == 'Reddit (Public/Retail)']
                        fig_trend.add_trace(go.Scatter(
                            x=reddit_trend['Date'], y=reddit_trend['Sentiment'],
                            mode='lines+markers', name='è®¨è®º (æ•£æˆ·/å…ˆè¡Œ)',
                            line=dict(color='#ff7f0e', width=3, dash='dot') # è™šçº¿è¡¨ç¤ºä¸ç¨³å®šæ€§
                        ))

                    fig_trend.update_layout(
                        title=f"'{topic}' èˆ†è®ºåˆ†æ­§å›¾ (Sentiment Divergence)",
                        yaxis=dict(title='æƒ…ç»ªææ€§ (-1 æ‚²è§‚, 1 ä¹è§‚)', range=[-1, 1]),
                        xaxis=dict(title='æ—¥æœŸ'),
                        hovermode="x unified",
                        legend=dict(orientation="h", y=1.1)
                    )
                    
                    # æ·»åŠ å‚è€ƒçº¿ (0è½´)
                    fig_trend.add_hline(y=0, line_dash="dash", line_color="gray", annotation_text="ä¸­æ€§åŸºå‡†")
                    
                    st.plotly_chart(fig_trend, use_container_width=True)
                    
                    # 5. è¯¦ç»†æ•°æ®å±•ç¤º (å¢åŠ ä¸»è§‚åº¦è¿‡æ»¤)
                    c1, c2 = st.columns(2)
                    with c1:
                        st.markdown("#### ğŸ“° æœºæ„æ–°é—» (Top News)")
                        if not df_news.empty:
                            st.dataframe(df_news[['Date', 'Text', 'Sentiment']].head(10), use_container_width=True)
                    
                    with c2:
                        st.markdown("#### ğŸ—£ï¸ æ•£æˆ·é«˜å™ªç‚¹ (High Subjectivity)")
                        st.caption("ç­›é€‰ä¸»è§‚åº¦ > 0.5 çš„è¨€è®ºï¼Œé€šå¸¸åŒ…å«å¼ºçƒˆæš—ç¤ºã€‚")
                        if not df_reddit.empty:
                            # ç­›é€‰é«˜ä¸»è§‚åº¦è¨€è®º
                            high_subj = df_reddit[df_reddit['Subjectivity'] > 0.5].sort_values('Sentiment')
                            st.dataframe(high_subj[['Date', 'Text', 'Sentiment']].head(10), use_container_width=True)
                            
                else:
                    st.warning("æœªæ‰¾åˆ°æ•°æ®ï¼Œè¯·æ£€æŸ¥ API Key æˆ–å°è¯•æ›´æ¢å…³é”®è¯ã€‚")